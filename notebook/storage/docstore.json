{"docstore/metadata": {"b99283e5-e776-49cd-93fb-238af4f75e2c": {"doc_hash": "25565c3caae9051e794eccefe8e91b494101f6ed88d547d7cf77ab33c43bc7df"}, "e010dd36-4403-4465-8e99-57c3731f58bc": {"doc_hash": "f54444c5780124a4b2c6c72c415ab8a4b1dff16351b95f6fc10ecc0d47b6c3b2", "ref_doc_id": "b99283e5-e776-49cd-93fb-238af4f75e2c"}, "f3527244-208b-4477-8fb9-c6d6406413f9": {"doc_hash": "79361121d2c6cdd18649b42d8a8b5b39f505687d137cf7e0b619bccc75c2291c", "ref_doc_id": "b99283e5-e776-49cd-93fb-238af4f75e2c"}, "76754694-ffda-4626-bead-f65634a98c7d": {"doc_hash": "c0496ef237185f186317f998c778f3715b9dc7d5bf30f10d46dbcbe26a1faae7", "ref_doc_id": "b99283e5-e776-49cd-93fb-238af4f75e2c"}, "10228bfc-8954-4b2c-9532-870d4d0618af": {"doc_hash": "9ac49ce7185bb28a1387de11ce29a9d848aa65d4e6cc1616a2bfcf21ff325f52", "ref_doc_id": "b99283e5-e776-49cd-93fb-238af4f75e2c"}}, "docstore/data": {"e010dd36-4403-4465-8e99-57c3731f58bc": {"__data__": {"id_": "e010dd36-4403-4465-8e99-57c3731f58bc", "embedding": null, "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b99283e5-e776-49cd-93fb-238af4f75e2c", "node_type": "4", "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "hash": "25565c3caae9051e794eccefe8e91b494101f6ed88d547d7cf77ab33c43bc7df", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f3527244-208b-4477-8fb9-c6d6406413f9", "node_type": "1", "metadata": {}, "hash": "e168dc4405c5676b3a19f198f87ce1f9add9d21beea1ed07d03d39a32fc36dd3", "class_name": "RelatedNodeInfo"}}, "text": "From Wikipedia, the free encyclopedia\n\"AI\" redirects here. For other uses, see AI (disambiguation), Artificial intelligence (disambiguation), and Intelligent agent.\nPart of a series on\nArtificial intelligence\n\nMajor goals\nApproaches\nApplications\nPhilosophy\nHistory\nGlossary\nvte\nArtificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] Such machines may be called AIs.\n\nSome high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[2][3]\n\nThe various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence\u2014the ability to complete any task performable by a human on an at least equal level\u2014is among the field's long-term goals.[4] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[5]\n\nArtificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism,[7][8] followed by periods of disappointment and loss of funding, known as AI winter.[9][10] Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture,[12] and by the early 2020s hundreds of billions of dollars were being invested in AI (known as the \"AI boom\"). The widespread use of AI in the 21st century exposed several unintended consequences and harms in the present and raised concerns about its risks and long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n\nGoals\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\n\nReasoning and problem-solving\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14]\n\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3906, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f3527244-208b-4477-8fb9-c6d6406413f9": {"__data__": {"id_": "f3527244-208b-4477-8fb9-c6d6406413f9", "embedding": null, "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b99283e5-e776-49cd-93fb-238af4f75e2c", "node_type": "4", "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "hash": "25565c3caae9051e794eccefe8e91b494101f6ed88d547d7cf77ab33c43bc7df", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e010dd36-4403-4465-8e99-57c3731f58bc", "node_type": "1", "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "hash": "f54444c5780124a4b2c6c72c415ab8a4b1dff16351b95f6fc10ecc0d47b6c3b2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "76754694-ffda-4626-bead-f65634a98c7d", "node_type": "1", "metadata": {}, "hash": "0a0cb412735dae881da9b43959d44a43fa5ceec9eff165139c71c3cc0d42904c", "class_name": "RelatedNodeInfo"}}, "text": "They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.\n\nKnowledge representation\n\nAn ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.\nKnowledge representation and knowledge engineering[17] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[18] scene interpretation,[19] clinical decision support,[20] knowledge discovery (mining \"interesting\" and actionable inferences from large databases),[21] and other areas.[22]\n\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[23] Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;[24] situations, events, states, and time;[25] causes and effects;[26] knowledge about knowledge (what we know about what other people know);[27] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[28] and many other aspects and domains of knowledge.\n\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[29] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).[16] There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.[c]\n\nPlanning and decision-making\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][32] In automated planning, the agent has a specific goal.[33] In automated decision-making, the agent has preferences\u2014there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[34]\n\nIn classical planning, the agent knows exactly what the effect of any action will be.[35] In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[36]\n\nIn some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences.[37] Information value theory can be used to weigh the value of exploratory or experimental actions.[38] The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\n\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state.", "mimetype": "text/plain", "start_char_idx": 3840, "end_char_idx": 7706, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "76754694-ffda-4626-bead-f65634a98c7d": {"__data__": {"id_": "76754694-ffda-4626-bead-f65634a98c7d", "embedding": null, "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b99283e5-e776-49cd-93fb-238af4f75e2c", "node_type": "4", "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "hash": "25565c3caae9051e794eccefe8e91b494101f6ed88d547d7cf77ab33c43bc7df", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f3527244-208b-4477-8fb9-c6d6406413f9", "node_type": "1", "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "hash": "79361121d2c6cdd18649b42d8a8b5b39f505687d137cf7e0b619bccc75c2291c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "10228bfc-8954-4b2c-9532-870d4d0618af", "node_type": "1", "metadata": {}, "hash": "97f9167972852ebfa6ef7ccdcecff37525482e614c7353f85c13c2847abeafc6", "class_name": "RelatedNodeInfo"}}, "text": "A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.[39]\n\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.[40]\n\nLearning\nMachine learning is the study of programs that can improve their performance on a given task automatically.[41] It has been a part of AI from the beginning.[e]\n\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[44] Supervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[45]\n\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".[46] Transfer learning is when the knowledge gained from one problem is applied to a new problem.[47] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[48]\n\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[49]\n\nNatural language processing\nNatural language processing (NLP)[50] allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[51]\n\nEarly work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation[f] unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem[29]). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\n\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[52] transformers (a deep learning architecture using an attention mechanism),[53] and others.[54] In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text,[55][56] and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[57]\n\nPerception\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[58]\n\nThe field includes speech recognition,[59] image classification,[60] facial recognition, object recognition,[61]object tracking,[62] and robotic perception.[63]\n\nSocial intelligence\n\nKismet, a robot head which was made in the 1990s; a machine that can recognize and simulate emotions[64]\nAffective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood.[65] For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human\u2013computer interaction.\n\nHowever, this tends to give na\u00efve users an unrealistic conception of the intelligence of existing computer agents.", "mimetype": "text/plain", "start_char_idx": 7650, "end_char_idx": 11479, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10228bfc-8954-4b2c-9532-870d4d0618af": {"__data__": {"id_": "10228bfc-8954-4b2c-9532-870d4d0618af", "embedding": null, "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b99283e5-e776-49cd-93fb-238af4f75e2c", "node_type": "4", "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "hash": "25565c3caae9051e794eccefe8e91b494101f6ed88d547d7cf77ab33c43bc7df", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "76754694-ffda-4626-bead-f65634a98c7d", "node_type": "1", "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}, "hash": "c0496ef237185f186317f998c778f3715b9dc7d5bf30f10d46dbcbe26a1faae7", "class_name": "RelatedNodeInfo"}}, "text": "However, this tends to give na\u00efve users an unrealistic conception of the intelligence of existing computer agents.[66] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.[67]\n\nGeneral intelligence\nA machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[4]\n\nTechniques\nAI research uses a wide variety of techniques to accomplish the goals above.[b]\n\nSearch and optimization\nAI can solve many problems by intelligently searching through many possible solutions.[68] There are two very different kinds of search used in AI: state space search and local search.\n\nState space search\nState space search searches through a tree of possible states to try to find a goal state.[69] For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[70]", "mimetype": "text/plain", "start_char_idx": 11365, "end_char_idx": 12455, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"b99283e5-e776-49cd-93fb-238af4f75e2c": {"node_ids": ["e010dd36-4403-4465-8e99-57c3731f58bc", "f3527244-208b-4477-8fb9-c6d6406413f9", "76754694-ffda-4626-bead-f65634a98c7d", "10228bfc-8954-4b2c-9532-870d4d0618af"], "metadata": {"file_path": "/Users/arsh/Desktop/qasystem/notebook/../Data/sample2.txt", "file_name": "sample2.txt", "file_type": "text/plain", "file_size": 12466, "creation_date": "2024-10-11", "last_modified_date": "2024-10-11"}}}}